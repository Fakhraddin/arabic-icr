%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
%\documentclass[12pt,english]{report}
%\usepackage{mathptmx}
%\renewcommand{\familydefault}{\rmdefault}
%\usepackage[T1]{fontenc}
%\usepackage[latin9]{inputenc}
%\usepackage[a4paper]{geometry}
%\setcounter{secnumdepth}{2} % Changed from 3 to 2. 0-chapter 1-section 2-subsection 
%\setcounter{tocdepth}{2} % Changed from 3 to 2. 0-chapter 1-section 2-subsection 
%\setlength{\parskip}{\medskipamount}
%\setlength{\parindent}{0pt}
%\usepackage{verbatim}
%\usepackage{pdfpages}
%\usepackage{graphicx}
%\usepackage{subfig} %% This package has to be here
%\usepackage{setspace}
%\usepackage{arabtex}
%\usepackage[numbers]{natbib}
%\usepackage{nomencl}
%\usepackage{amsthm}
%\usepackage{amsmath}
%\usepackage{amsfonts}
%\usepackage{paralist}
%\usepackage{etoolbox}
%\newtoggle{edit-mode}
%\toggletrue{edit-mode}  
%%%\toggletrue{edit-mode}
%\iftoggle{edit-mode}{
%\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=6cm,headheight=1cm,headsep=1cm,footskip=1cm, marginparwidth=5cm}
%}{
%\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm,headheight=1cm,headsep=1cm,footskip=1cm}
%}
%
%
%\begin{document}

%%%%%%%%%%% nomenclature %%%%%%%%%%
\nomenclature{HWR}{Handwriting recognition}
\nomenclature{OCR}{Optical character recognition}
\nomenclature{WP}{Word part}
\nomenclature{ANN}{Artificial neural networks}
\nomenclature{SVM}{Support vector machine}
\nomenclature{$k$-NN}{$k$-nearest neighbours}
\nomenclature{SP}{segmentation point}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\section{Background and Previous Work}

\subsection{Handwriting Recognition}
\iftoggle{edit-mode}{\hspace{0pt}\marginpar{HWR Motivation 1 - handwriting importance and survival}}{}
Writing has made much of the culture and civilization possible.
It was developed as a mean to expand human memory and to facilitate communication. 
Despite the long standing prediction that digital computers will challenge its future, handwriting remains a commonly used mean for communication and recording of information in the daily life; the pen and paper are still the natural medium for many important tasks such as notes taking in class. 
Therefore, a growing interest in the \emph{handwriting recognition} (HWR) field has emerged in recent years, and has now been a topic of research for over four decades.


\iftoggle{edit-mode}{\hspace{0pt}\marginpar{HWR Motivation 2 - ease of digital representation and Keyboard-less devices}}{}
Converting handwritten script into its digital analogous is highly motivated by the ease and convenience of the digital representation.
Not only this is useful for making digital copies of handwritten documents, but also in many automated processing tasks such as searching, indexing, automatic mail sorting, editing, sharing and more \cite{noaparast2009persian}.
Another motivation for recognizing handwritten scripts is the rapid transition from personal computers and laptops to the usage of keyboard-less smart-phone and table devices that are too small to have convenient keyboard, and thus, requiring pen or finger gestures to enter data \cite{connell2000online}. 

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{HWR as OCR}}{} 
HWR was defined as "the task of transforming a language represented in its spatial form of graphical marks into its symbolic representation" by Plamondon and Srihari \cite{plamondon2000online}.
HWR is a special case of \emph{optical character recognition} (OCR), an important field in pattern recognition that is defined as the science of electronically converting a scanned, photographed, or sensed of both typewritten or printed texts, into machine-encoded text. OCR has been steadily evolving during its history and has always been a favorite testing ground for new ideas in pattern recognition, giving rise to an exciting set of research topics and producing many powerful practical applications.
However, since many experiments of new ideas in pattern recognition were conducted on isolated characters, the results are not always immediately reflected in OCR applications \cite{burrow2004arabic}  .
OCR is considered one of the best applications of machine vision and one of the most successful research branches in pattern recognition theory. 
Although considered a well developed technological field, OCR remains an area of active scientific research and creative engineering \cite{borovikov2004survey}.
Besides recognition, handwriting is associated with other types of analysis, such as signature verification, writer identification, etc.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Levels of difficulties in HWR}}{}
There are different types of problems with varying complexity within HWR, depending on how the data is presented to the recognition system, at what level the data can be unambiguously broke into pieces (e.g. individual characters or words), and the transcription complexity of the language used \cite{bahlmann2005advanced}. 
In one extreme there is the case of isolated characters written inside graphical boxes in which the segmentation problem is already solved. The opposite extreme is the case of cursive unrestricted handwriting in which words, or portion of a word, is written with a single stroke, i.e, ligatures connect adjacent letters. HWR systems have a strong history in making use of this graduation in difficulty \cite{bahlmann2005advanced}. 

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{State of the Art HWR}}{}
\emph{TODO: take that from the book.}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Arabic HWR challenge}}{}
A script is a set of icons that have certain basic shapes. 
These are known as characters or letters.
Each script has its own rules regarding how letters are combined to form shapes that represent higher level linguistic units \cite{plamondon2000online}.
Unlike the Latin script, in which non-cursive handwriting, i.e., using isolated characters, is possible and common, Arabic is cursively written in both handwritten and printed text.
Its unconstrained nature, which produces a huge variety in the handwriting of different people, makes the recognition of Arabic script extremely difficult.
Figure \ref{fig:ha_different} shows several handwritten samples the letter \RL{.h} /.h/, in its isolated form, written by several writers.
Text segmentation, that is, the process of dividing a cursive writing into sub-units (typically characters) turns out to be a challenging task.

\begin{figure}
\centering
\includegraphics{./figures/ha_different}       
\caption{Different writing styles of the isolated form of the letter \RL{.h}.}
\label{fig:ha_different}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Off-line versus On-line Handwriting Recognition}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Introduction}}{}
The field of HWR can be classified in several ways. However, the most common categorization is the one that distinguishes between \emph{off-line} (also called static) and \emph{on-line} (also called dynamic).
Off-line HWR focuses on documents that have been written on paper at some previous point of time. A digital image of the document is fed to the computer, and the system attempts to convert the spatial representation of the letters into digital symbols \cite{al2011online}. 
In contrast, on-line HWR is performed on a digital representation of the text written on a special digitizer, tablet or smart-phone device, where sensors pick up the pen-tip movements and the two-dimensional coordinates of successive points of the writing as a function of time are stored.
Figure \ref{fig:offline_vs_online} shows typical input signals that can be analyzed in both cases.

\begin{figure}
	\centering
        \subfloat[]{
            \label{fig:offline}
            \includegraphics[width=0.5\textwidth]{./figures/offline}
        }
        \subfloat[]{
           \label{fig:online}
           \includegraphics[width=0.5\textwidth]{./figures/online}
        }        
    \caption{An on-line vs. an off-line representation of a word \cite{plamondon2000online}.}
   \label{fig:offline_vs_online}
\end{figure}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Literature}}{}
The research on on-line handwriting recognition started in the 1960's and has been receiving a great interest from the 1980's \cite{tagougui2013online}.
One of the earliest studies on On-line Arabic script recognition was carried out by El-Wakil and Shoukry in 1989 \cite{el1989line}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Similarities and advantages of on-line and off-line}}{}
Off-line HWR techniques can be applied to on-line data by constructing a static image of the on-line script. 
However, it has been shown that the information of the pen dynamics, such as the strokes breaking (i.e., "pen-down" and "pen-up" events) and the order of writing, can be used to obtain a better recognition accuracies than the static data alone. 
In the other direction, the success of on-line systems makes it attractive to consider developing off-line systems that first estimate the trajectory of the writing from the off-line data and then use on-line HWR techniques. 
Nevertheless, reconstructing the temporal data is problematic, and thus, has led to few such systems so far \cite{plamondon2000online}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{off-line objectives}}{}
In general, off-line HWR systems are less accurate than on-line systems, but, they are now good enough that they have a significant economic impact on specialized domains such as interpreting handwritten postal addresses on envelopes and reading courtesy amounts on bank checks \cite{melin2007analysis}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{A general flow for HWR}}{}
Despite the large variation among the different methods for HWR, there are several fundamental stages that are common between most of the systems.
The data acquisition step is the first stage in HWR. 
In the on-line case, the stylus motion is sampled at equal time intervals.
The samples go through a preprocessing stage that includes filtering of noises, re-sampling the stroke information to obtain equidistant stroke, and normalized to a standard size. 
Additional preprocessing may include slant and slope corrections. 
Then, depending on the nature of the system, the script may undergo segmentation into basic units that could be words, parts of words, single characters or graphemes.
Typically, a feature extraction technique is then applied to extract significant and distinguishing attributes of the input data.
Using a classification algorithm the basic units are labeled. 
In many cases, a post-processing stage is applied in which the language model is used to search for the most likely string in the lexicon.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{off-line HWR additional steps}}{}
Approaches for on-line and off-line handwriting recognition, while having much in common, are different, due to the disparity in the input data representation. 
Their different nature imposes different challenges and thus variable levels of efforts are required to be spent on the various stages.
The off-line HWR systems usually consist of additional steps of layout analysis and text lines extraction, which are activated at the beginning of the preprocessing stage. 
Each text line is then divided into words or WPs. 
The segmentation, in such system, is made into images that contain basic units. 
The whole process is straightforward for well printed or well written documents; however, in the case of historical or badly printed document much effort is invested in a preprocessing stage that include smoothing, writing flow reconstruction, purification, and more \cite{saba2010survey}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Holistic versus the Analytic Approach}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Importance of the dictionary size}}{}
The vocabulary, from which the words in the test set are taken, has a major impact on how difficult the HWR task is.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Closed and open vocabulary definitions}}{}
Closed-vocabulary HWR systems are capable of recognizing words from a predetermined limited size dictionary. 
The restricted vocabulary set is usually called a lexicon.
There are no well-established criteria for the categorization of lexicon size. 
However, the following terms are usually used:
\begin{compactitem}
\item small lexicon - tens of words.
\item medium lexicon - hundreds of words.
\item large lexicon - thousands of words.
\item very large lexicon - tens of thousands of words.
\end{compactitem}
Open-vocabulary tasks refer to the recognition of any word without the constraint of being in a dictionary.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Recognition difficulty}}{}
The lexicon is a key-point post-processing stage in many systems, because the linguistic knowledge helps to filter out many possible options that are not included in the lexicon, and consequently raises the recognition rate.
The adhesion to a limited dictionary, may also limit the computational complexity. 
Although most research efforts have been devoted to closed vocabulary systems, open vocabulary systems have also been proposed.
Yet, their accuracy is still far below those relying on a small vocabulary \cite{koerich2003large, shu1996line}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{problems imposed by the open vocabulary}}{}
While there exists a wide variety of approaches to cursive script recognition, research in this field has established two main approaches, one is the analytic approach \cite{abdulla2008off, sari2002off, dinges2011offine, elanwar2012unconstrained}, and the other is the holistic approach \cite{biadsy2011segmentation}. 


The analytic approach involves segmentation of the input curve into basic units and the classification of each individual unit.
The advantage of this approach is that it requires to maintain only a small set of trained models - one for each letter shape - to handle large vocabulary. 
However, the absence of consistent baselines, large variations in writing styles, and seamless connection between letters (connection is done with almost no ligatures) makes segmentation into individual letters very challenging \cite{saabni2009hierarchical}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The holistic approach}}{}
The holistic approach considers the global properties of the written text and recognizes the input word shape as a whole. 
Most popular methods among this group are based on analysis of the number and order of ascenders, descenders, loops and vertical strokes; they often rely on heavy dictionary searching that is costly and prone to be mislead by spelling errors \cite{brodowska2011oversegmentation}.
While it avoids the error-prone segmentation process, in the holistic approach, the recognition system needs to be trained over all words in the dictionary and to maintain and train models for each word. 
Using the holistic approach may be possible for a small vocabulary of words, however, this is not feasible for large vocabularies (20,000 words or more). 
Since each word is constructed from a subset of the character alphabet, it is much more efficient to classify words using the analytic approach \cite{elanwar2012unconstrained}.
In addition, a survey done in \cite{al2011online} on Arabic HWR found that the analytic approach, in general, achieve higher recognition rates than the holistic systems, in cases where words are written in cursive manner, such in the Arabic script. 
This may lead us to conclude that segmentation is a crucial step and that the main problem recognizing Arabic text, especially its handwriting, is its cursiveness.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Arabic Handwriting Recognition}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The Arabic spread}}{}
The Arabic script is one of the descendants of the Aramaic script. 
The earliest known document written using the Arabic script dates from 512 AD.  
The Arabic language is spoken, as their first language, by nearly 350 million people around the world , and written by more than 100 million people, in over 20 different countries \cite{zeki2011segmentation}.
This makes it one of the five most common languages in the world and one of the six United Nations official languages since 1974 \cite{burrow2004arabic}. 
Although Arabic is used mainly in the Arab countries, which consists of about 5.5\% of the world population, almost all Muslims, around 25\% of the world population can read Arabic script as it is the language of the Holy Qur'an \cite{zeki2011segmentation}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The Arabic Alphabet usage in other languages}}{}
The use of Arabic language extended in the 7th and 8th centuries from India to the Atlantic ocean due to the Islamic conquests \cite{saabni2009efficient}. 
Consequently, more than twenty different languages adopted the Arabic alphabet with some changes. 
Examples of such languages are Farsi, Urdu, Malay, Housa and Ottoman Turkish.
Nevertheless, some of those languages has later adopted the Latin characters, but in general, people can still read the Arabic script \cite{zeki2011segmentation}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Literary vs. daily language}}{}
Although spoken Arabic is different from country to country, written Arabic is a standard system used all over the Arab world.
The literary language is called \emph{modern standard Arabic} or \emph{literary Arabic}, which it is currently the only official form of Arabic, used in most written documents as well as in formal spoken occasions, such as lectures and news broadcasts. 

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The growing interest in the Arabic HWR}}{}
The first work on Arabic character recognition is by Nazif \cite{nazif1975system} published in 1975, while the earlier research efforts in Latin may be traced back to the middle of the 1940s.
However, considerable increase in the number of research papers related to Arabic character recognition is evident in recent years.
The challenging nature of HWR has attracted the attention of researchers from industry and academic circles \cite{al2010development, zeki2011segmentation}.
A recent survey done by Tagougui et al. \cite{tagougui2013online} reviews the status of research in the on-line Arabic handwriting recognition field. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Characteristic of the Arabic Writing System}
\label{subsubsec:arabic_writing_characteristic}


\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Basic properties}}{}
The Arabic script consists of 28 basic letters and is written from right to left in a semi-cursive manner in both printed and handwritten forms.
Most letters are written in four different letter shapes depending on their position in the word, e.g., the letter \RL{`}  (Ain) appears as \RL{`}  in its isolated form, \RL{`-} in its initial form, \RL{-`-} in its medial form and \RL{-`} in it final form. 
Among the basic letters, six are Dis-connective - \RL{A} /a/, \RL{d} /d/, \RL{_d} /th/, \RL{r} /r/  \RL{z} /z/ and \RL{w} /w/. 
Dis-connective letters do not connect to the following letter and have only two shapes each, isolated and final. 
The presence of these letters interrupts the continuity of the graphic form of a word. 
The parts of the word that are graphically connected are called \emph{word parts} (WPs). 
If the WP is composed of only one letter, this letter will be in its isolated shape \cite{biadsy2011segmentation}. 

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Delayed strokes}}{}
Certain characteristics relating to the obligatory dots and strokes of the Arabic script, distinguish it from Latin script.
These dots and strokes are called \emph{delayed strokes} since they are usually drawn last in the when scribing a WP or a word. 
There are mainly two types of delayed strokes, \emph{i'jam} (\RL{A`jAm}) and \emph{harakat} (\RL{.hrkAt}). 
The old Arabic was written without dots or diacritics. 
These additional strokes that were added to the Armaic letters, were first introduced around the 7th century, to prevent the Qur'an from being misread by Muslims \cite{burrow2004arabic}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{I'jam}}{}
The i'jam are the pointing diacritics added to the main body of the letter (called rasm) and their role is to distinguish between various constants ,such as, the medial form letters \RL{-b-} /b/, \RL{-t-} /t/, \RL{-_t-} /s/, \RL{-n-} /n/, \RL{-y-} /y/.
Typically, i'jam are not considered diacritics but part of the letter and consists of one or more dots and lines added above, under or inside the letter.
Eliminating, adding or moving a i'jam produces a completely different letter and as a result a completely different word, thus, they are not omitted in the written documents.
Not only dots are used as i'jam, the \RL{'} (hamza) is another type of i'jam that distinguish between the letters \RL{k} /k/ and \RL{l} /l/ in their isolated and final forms.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Harakat}}{}
The harakat are small markings added above or below the letters, are used to specify the exact pronunciation of the word.
These diacritics are used in the holy book Qur'an and are commonly used in teaching material and poetry but are seldom used in day-to-day communication and handwriting neither are much in use in the scientific, and business communication.

An example of a fully vocalised Arabic from the Qur'an (Al-Fatiha 1:1):

\begin{center}
\fullvocalize
\transtrue
\begin{RLtext}
bismi al-ll_ahi al-rra.hm_ani al-rra.hImi
\end{RLtext}
In the Name of All'ah, the Most Gracious, the Most Merciful...
\end{center}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{additional stroke}}{}  
In our work we recognize and classify the main body of the letter and ignore the additional stroke entirely. 
As a result, the number of different letters drops from 29 to 18.
It is important to note that taking the delayed strokes into consideration may be exploited to boost the classification rate.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{WP count}}{}    
Saabni and El-sana \cite{saabni2009efficient} have explored a large collection of Arabic texts and extracted 300,000 different word combinations of 82,000 different WPs.
Ignoring the delayed strokes, the number of different WP had reduced to 40,000. 

%\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Challenges of the Arabic language}}{}  
%The main body of most Arabic letters is written by a single stroke. A single stroke can contain a single or multiple letters.
%However, there are some letters that usually written using two strokes, such as the letter \RL{-k-}  which is the middle form of the letter \RL{k} /k/. 
%The writer usually writes \RL{-l-} and adds the final upper slanted line when the main body is completed, as if he writes an additional stroke.
%Another problem arises when trying to recognize Arabic transcript, is that, different writers may write the main body of the same word part in a different number of strokes. 
%As can be seen very similar to the \RL{s} /s/ letter in its medial position \RL{-s-}, the only to distinguish between the two options is by looking at the additional strokes.
%For these mentioned complexities, when recognizing Arabic scripts, many researches have preferred the holistic approach. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Arabic Letters classification}
\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The learning problem.}}{}
Classification is the problem of identifying to which of a set of classes an unlabelled observation belongs. 
In the case of \emph{supervised learning}, the classification is performed based on a training set of data containing labelled samples, as defined in \ref{def:supervised_learning}.
\begin{definition}
Given a domain space $X$, a target space $Y$ and a training set $S=\{(x_i,y_i)\}_{i=1}^{m}$ where $x_1,x_2,..,x_n\in X$ and $y_1,y_2,...,y_n \in Y$. Let us assume that there is an unknown target function $f$ for which $f : X\rightarrow Y$. A Learning algorithm $A$ produces hypothesis function $h$ based on $S$ such that $h \approx f$, i.e., the function $h$ is an approximation for the target function $f$ and $h \in H$, the hypotheses set. 
\label{def:supervised_learning}
\end{definition}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{./figures/machine_learning_diagram}       
\caption{A learning algorithm scheme}
\label{fig:machine_learning_diagram}
\end{figure}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The classification problem}}{}
Given a classification problem, there is an intuitive belief that there exist a space to which the samples can be transformed and in which can be portioned into regions that represent categories. 
Accordingly, the problem of classification is basically the problem of portioning the sample space into regions. 
Having done that, classifying a new unlabelled observation is done by determining the partition it belongs to. 
Ideally, one would like to arrange this partitioning so that none of the decisions is ever wrong. 
When this cannot be done, one would like to minimize the probability of error \cite{duda1973pattern}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Types of approaches in the supervised Learning.}}{}
Many supervised learning approaches and algorithms were proposed to solve the classification problem. 
\emph{Decision trees}, \emph{artificial neural networks} (ANN), \emph{support vector machines} (SVMs), \emph{Bayesian networks} and \emph{$k$-nearest neighbours} ($k$-NN) are few well-known learning techniques. 
A review on the supervised classification algorithms is given by Mohamed Aly in \cite{aly2005survey}. 
The role of the machine learning specialist is to identify the type of the learning problem and meet the needs of the problem by stitching the best solution for it.


\iftoggle{edit-mode}{\hspace{0pt}\marginpar{HWR Complexity}}{} 
HWR is one of the very complex and challenging problems in the pattern recognition field.
This is, mainly, due to the variation of shapes of the characters resulting from writing habits, styles, and the social and educational level of the writer.
Other factors which implicate the recognition is the variability of writing styles, cursive writing, text size differences and sampling issues, such as duplicate samples resulted from hesitate writers as well as non-adjacent consecutive samples caused by fast writers \cite{verma2004feature}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Letter classification using HMM}}{}
Unlike in the off-line case, on-line handwriting can be viewed as temporal series, therefore many pattern recognition techniques from the temporal information field were adopted for handwriting recognition. 
One example is the \emph{hidden Markov models} (HMM), an extension of the discrete-state Markov process.
There is a vast amount of studies done in the field of HWR that use HMM \cite{pechwitz2003hmm, khorsheed2003recognising, al2007combination, benouareth2008arabic, mahmoud2008recognition, shu1996line, biadsy2006online}. 
Letters, words and sentences can be modelled using HMM and classified using the solution to the learning problem.
For the interested reader unfamiliar with HMMs, we recommend the following two references \cite{kadous2002temporal, shu1996line}, for a well-written introduction.
While having many advantages, there are some drawbacks of using HMM Kondous has pointed out in his Ph.D thesis \cite{kadous2002temporal}. 
The HMM model makes some powerful assumption about the data that may not necessarily true. 
First, is the Markovian assumption that assumes the transition probabilities depend only on the current state. 
Second, there is no specific way to determine the number of states, thus intelligent guesses and try and error are usually employed. 
The third drawback is that the states and transitions depend on the class being learned. 
For example, is there any reason why the words "dog" and "butterfly" would have similar states and transitions? 
Forth, HMM requires a very large amount of data for its training.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The analytic approach}}{}
Many types of techniques were investigated for classifying Arabic characters, including artificial neural networks \cite{alijla2012oiahcr}, decision trees \cite{ismail2012online}, Hidden Markov Models \cite{biadsy2006online} and $k$-NN \cite{elglaly2011isolated}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The k-NN classifier}}{}
The $k$-nearest neighbours algorithm ($k$-NN) is a well-known classification technique in supervised learning. 
It predicts the query objects class memberships based on the $k$ closest training examples. 
The $k$-NN algorithm is one of the simplest of all machine learning algorithms: an object is classified by a majority vote of its neighbours, with the object being assigned to the class most common amongst its k nearest neighbours ($k$ is a positive integer, typically small). 
If $k=1$, then the object is simply assigned to the class of that single nearest neighbour. 
In many cases the notion of similarity between sample object is obvious, however in many other interesting cases the distance between objects cannot be easily defined.
Beside its simplicity, $k$-NN has some major advantages. 
First, $k$-NN is a good learning method for complex target functions. Second, it is easy to implement. 
Third, arbitrary objects similarity function can be applied easily.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Advantages and Downside of the $k$-NN classifier}}{}
$k$-NN algorithm has dome drawbacks that reader needs to note. $k$-NN needs a large data set in-order to achieve high classification accuracy. Another drawback is that it is very sensitive to data errors and can be easily fooled by outliers.


\subsection{Arabic Script Segmentation}

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Introduction}}{}
An integral part of the handwriting recognition process, when the analytic approach is considered, is segmentation. 
Therefore, it has long been a critical area of the OCR process. 
As for many pattern recognition problems, the task of segmentation, while usually trivial to a human to perform, is a very challenging pattern recognition problem.
Segmentation and recognition of cursive text are two tasks intertwined and dependent on each other. 
It is believed that wrong segmentation will often results in major contribution to the error of the recognition algorithm \cite{brodowska2011oversegmentation}. 
But, in order to determine the segmentation, the system may try to seek a pattern that will match a member of the system's alphabet \cite{casey1996survey}.
The segmentation task of cursive and unconstrained nature of languages such as Arabic, makes the segmentation task even harder.  
Several segmentation approaches have been proposed in the literature for Arabic OCR, yet, correct and efficient segmentation of the Arabic text is not easily achievable and considered to be a challenging problem even for printed text. 

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{The context dependent of segmentation}}{}
Reliable recognition system requires more than a good matching to a set of letters symbol classes.
The segmentation decision is not a local decision and may affect subsequent segmentation decisions, thus, a poor match of the current segment to some class in the letter library can cast doubt on the correctness of the future segmentation decisions.
In addition, even a series of satisfactory pattern matches can be judged incorrect if contextual requirements of the system output are not satisfied \cite{casey1996survey}.
For instance, in handwritten English, the letter combination "cl" is graphically similar to the letter "d", but in some cases contextually not valid.
In Arabic, two or three consequent appearances of rasm \RL{-b-} /b/ (that is common for the letters \RL{-y-} /y/, \RL{-t-} /t/ and more, see Section \ref{subsubsec:arabic_writing_characteristic}) are very similar to the \RL{-s-} /s/ letter. 
The only way to distinguish between the two options is by considering the delayed strokes and the contextual validity.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Approaches for segmentation}}{}
In a comprehensive survey done in \cite{casey1996survey}, the authors has pinpointed two elemental strategies for off-line cursive text segmentation in addition to many approaches that are combinations of these three. 
They have noted that much of the literature on segmentation reports methods that can be characterized as a blend of these three mentioned methods.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Dissection}}{}
The first strategy is the classical approach, which is usually named \emph{dissection}, attempts are made to segment the text into primitives. 
Dissection techniques attempt to find appropriate candidate points by learning the characteristic of the segmentation point or by using a rules-based engine. 
Segments, that result from the segmentation process, do not necessarily correspond to exactly one character. 
The word could be segmented into components called graphemes, which are a combination of two or three letters, or a part of a letter. 
The relationship between graphemes and letters is applied in a later phase. 
Many morphological properties were exploited for this task, such as, height, width, separation from neighboring components, low slope if the candidate point local environment, etc.
Various strategies such as projection profile, bounding box or contour tracing exhibit promising results. 
Different types of scripts with essential distinctive nature usually require using different type of properties.
For instance, local minima in the upper or lower contour is commonly used for segmenting English cursive script but not in the Arabic script. 
Such approaches can segment typical words accurately, but, might lead to incorrect segmentation when deal with unconstrained cursive handwriting \cite{saba2010survey}.
A common approach that is followed by many researchers is first over-segmenting of the text, i.e, finding some set of potential splitting points that partition the handwritten word into primitives and then be processed further to eliminate improper candidates point \cite{daifallah2009recognition}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Recognition-based segmentation}}{}
The second approach is the recognition-based segmentation, in which the system searches for sub-components in the cursive text that match letters in its alphabet. 
As mentioned before, character segmentation and character classification are not totally separate steps with a varying degree of dependency.
The initial selection of points can be made in a variety of methods. 
For example, using a moving window with a predefined width which breaks the word into many overlapping pieces without regard to its content.
Then, an iterative or parallel recognition method is used to search for "satisfactory" classification scoring for joint sub-components usually by generating a lattice of all or many possible combinations of the initial candidates set. 
The final decision is determined by the best path through the lattice. 
While avoiding using complex dissection methods, such techniques rely heavily on the classifier accuracy which heavily affects the overall segmentation accuracy \cite{casey1996survey}.

\iftoggle{edit-mode}{\hspace{0pt}\marginpar{Literature Review}}{}
Randa et al. \cite{elanwar2012unconstrained} proposed a two stage on-line Arabic handwritten text segmentation system based on Hidden Markov Model (HMM). 
In the first stage, SPs were nominated, and then, in a second stage, the nominated points were validated using a rules-based engine. 
The system was tested using a self-collected database named OHASD.
Segmentation-based recognition approach based on dividing the word into smaller pieces was proposed in \cite{dinge2011offine}. 
The words were afterwards segmented into candidate letters, and then classified into letter classes, using statistical and structural features. 
A $k$ nearest neighbor ($k$-NN) classifier was used to obtain the final recognition.
A segmentation-based recognition method that operates on the stroke level for on-line Arabic handwritten words recognition was proposed by Daifallah et al. \cite{daifallah2009recognition}. 
SPs were nominated and then selected by locating semi-horizontal lines moving from right to left. 
A portion of the SPs is filtered out by applying a certain set of rules. 
Then, HMM is used to classify the sub-strokes to letters using the Hu feature. 
The letters candidates and their scoring were used to determine the best set of SPs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Thesis Scope and Outline}

In this thesis, we propose and implement a novel real-time approach for segmenting and recognizing on-line handwritten Arabic script.
In Chapter \ref{chap:characters_classification}, we present a fast approach for Arabic characters classification.
The characters classifier employs state-of-the-art similarity measure and search techniques for fast and accurate classification of characters.
A real-time, stroke level, recognition-based, segmentation technique is detailed in Chapter \ref{chap:strokes_segmentation}.
We present a procedure for nominating segmentation points whilst the stroke is being scribed and proposed algorithms for selecting the final segmentation set of segmentation points.
The results obtained by the classification system and the segmentation process are presented in Chapter \ref{chap:results}.
A summary and planned future work are given in Chapter \ref{chap:summary}. 

The ADAB database is the only and a de-facto standard database for on-line Arabic Handwritten script which provides a large sample set of handwritten words. 
Obtaining a large set of Arabic letters samples required the development of a manual segmentation system of samples taken from the ADAB database.
The system and the segmentation process are described in Appendix \ref{app:data_collection}.
The characters database created in this work can be used to facilitate future research in Arabic HWR.
A brief explanation on wavelets and the wavelet transform is given in Appendix \ref{app:wavelets}. 

The system has several assumptions and limitations.
First, it does not regard additional strokes although they can be used to improve the classification results.
Second, the analysis is performed independently on each stroke thus the system does not handle letters spanned over multiple strokes. 
While this is a reasonable assumption, it is not always true. 
Our future work will focus on waiving these limitations. 

%\bibliographystyle{plainnat}
%\bibliography{references}
%\end{document}